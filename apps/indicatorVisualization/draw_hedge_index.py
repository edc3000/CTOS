import random
import psutil
import sys
import pandas as pd
import numpy as np
from tqdm import tqdm
import time
import warnings
import os
import json
from datetime import datetime, timedelta
import gc
import matplotlib.pyplot as plt
import seaborn as sns
from scipy.signal import savgol_filter    # pip install scipy
import itertools
import mkl; mkl.set_num_threads(1)
from numpy.linalg import lstsq
from sklearn.preprocessing import StandardScaler
from sklearn.metrics.pairwise import euclidean_distances, cosine_similarity
from sklearn.cluster import SpectralClustering



try:
    import matplotlib.pyplot as plt
    import mplfinance as mpf
except Exception as e:
    print(e)
import threading
from collections import defaultdict
import gzip, pickle, copy
from pathlib import Path


SERVER_IP = os.getenv('HOST_IP', '')
if not SERVER_IP:
    SERVER_IP = input('è¯·è¾“å…¥æœåŠ¡å™¨IP: ')
    
def add_project_paths(project_name="ctos", subpackages=None):
    """
    è‡ªåŠ¨æŸ¥æ‰¾é¡¹ç›®æ ¹ç›®å½•ï¼Œå¹¶å°†å…¶åŠå¸¸è§å­åŒ…è·¯å¾„æ·»åŠ åˆ° sys.pathã€‚
    
    :param project_name: é¡¹ç›®æ ¹ç›®å½•æ ‡è¯†ï¼ˆé»˜è®¤ 'ctos'ï¼‰
    :param subpackages: éœ€è¦æš´éœ²çš„å­åŒ…åˆ—è¡¨ï¼ˆé»˜è®¤ ["ctos", "bpx", "okx", "backpack", "apps"]ï¼‰
    """
    if subpackages is None:
        subpackages = ["ctos", "bpx", "okx", "backpack", "apps"]
    current_dir = os.path.dirname(os.path.abspath(__file__))
    project_root = None
    # å‘ä¸Šå›æº¯ï¼Œæ‰¾åˆ°é¡¹ç›®æ ¹ç›®å½•
    path = current_dir
    while path != os.path.dirname(path):  # ä¸€ç›´å›æº¯åˆ°æ ¹ç›®å½•
        if os.path.basename(path) == project_name or os.path.exists(os.path.join(path, ".git")):
            project_root = path
            break
        path = os.path.dirname(path)
    if not project_root:
        raise RuntimeError(f"æœªæ‰¾åˆ°é¡¹ç›®æ ¹ç›®å½•ï¼ˆåŒ…å« {project_name} æˆ– .gitï¼‰")
    # æ·»åŠ æ ¹ç›®å½•
    if project_root not in sys.path:
        sys.path.insert(0, project_root)
    # æ·»åŠ å­åŒ…ç›®å½•
    for pkg in subpackages:
        pkg_path = os.path.join(project_root, pkg)
        if os.path.exists(pkg_path) and pkg_path not in sys.path:
            sys.path.insert(0, pkg_path)
    return project_root
# æ‰§è¡Œè·¯å¾„æ·»åŠ 
PROJECT_ROOT = add_project_paths()
print('PROJECT_ROOT: ', PROJECT_ROOT, 'CURRENT_DIR: ', os.path.dirname(os.path.abspath(__file__)))


def get_current_file_path() -> str:
    """è¿”å›å½“å‰æ–‡ä»¶çš„ç»å¯¹è·¯å¾„"""
    return os.path.abspath(__file__)

def get_current_dir() -> str:
    """è¿”å›å½“å‰æ–‡ä»¶æ‰€åœ¨çš„ç›®å½•"""
    return os.path.dirname(os.path.abspath(__file__))



print(PROJECT_ROOT)
from ctos.drivers.okx.util import BeijingTime, get_host_ip, rate_price2order, pad_dataframe_to_length_fast
from ctos.drivers.okx.driver import init_OkxClient as get_okexExchage
# === é…ç½® ===
COINS = list(rate_price2order.keys())
# TIMEFRAMES = {
#     '1m': 10/len(COINS),  # æ¯ 1 ç§’æ‹‰ä¸€æ¬¡
#     '5m': 1,  # æ¯ 5  ç§’æ‹‰ä¸€æ¬¡
#     '15m': 2,
#     '1h': 4,
#     '4h': 6,
#     '1d': 8
# }

TIMEFRAMES = {
    '1m': 20/len(COINS),  # æ¯ 1 ç§’æ‹‰ä¸€æ¬¡
    '5m': 2,  # æ¯ 5  ç§’æ‹‰ä¸€æ¬¡
    '15m': 4,
    '1h': 6,
    '4h': 8,
    '1d': 10,
}


# TIMEFRAMES = {
#     '1m': 3,  # æ¯ 1 ç§’æ‹‰ä¸€æ¬¡
#     '5m': 6,  # æ¯ 5  ç§’æ‹‰ä¸€æ¬¡
#     '15m': 10,
#     '1h': 20,
#     '4h': 40,
#     '1d': 80
# }

HOST_IP = get_host_ip()
KLINE_LENGTH = 300

# åµŒå¥—å­—å…¸  shared[timeframe][coin] = latest_df
shared_data = defaultdict(dict)
lock = threading.Lock()
lock_for_apis = threading.Lock()
exchange = get_okexExchage('eth', show=False)

MEMORY_LIMIT_MB = 1024*8  # 4GBå†…å­˜é™åˆ¶
CPU_LIMIT_PERCENT = 95  # CPUä½¿ç”¨ç‡é˜ˆå€¼

# ---------- è°ƒè‰²ç›˜ & çº¿å‹å¾ªç¯ ----------------------------------------
color_cycle = ['#1f77b4','#ff7f0e','#2ca02c','#d62728',
               '#9467bd','#8c564b','#e377c2','#7f7f7f',
               '#bcbd22','#17becf','#00c4ff','#ff9f00']
ls_cycle    = ['-','--','-.',':']

color_iter = itertools.cycle(color_cycle)
ls_iter    = itertools.cycle(ls_cycle)
balance_file_path = get_current_dir() + '/' +'total_balance.json'



SNAP_DIR = Path(get_current_dir()) / 'hourly_snapshots'
SNAP_DIR.mkdir(parents=True, exist_ok=True)

def _snapshot_filename(ts: datetime) -> Path:
    """ç”Ÿæˆå½¢å¦‚ 2025-07-03_14.pkl.gz çš„æ–‡ä»¶è·¯å¾„"""
    return SNAP_DIR / ts.strftime('%Y-%m-%d_%H.pkl.gz')

def save_snapshot(shared_data: dict):
    """æ·±æ‹·è´åå‹ç¼©ä¿å­˜"""
    ts   = datetime.utcnow()
    path = _snapshot_filename(ts)
    obj  = copy.deepcopy(shared_data)      # é˜²æ­¢å†™ç›˜æ—¶æ•°æ®è¢«æ”¹
    with gzip.open(path, 'wb') as f:
        pickle.dump(obj, f, protocol=pickle.HIGHEST_PROTOCOL)
    print(f"[{ts:%F %T}] ğŸ”’ snapshot saved â†’ {path.name}")

def load_last_snapshot():
    """è¯»å–æœ€è¿‘ä¸€å°æ—¶å¿«ç…§ï¼ˆè‹¥ä¸å­˜åœ¨è¿”å› Noneï¼‰"""
    now = datetime.utcnow()
    last_hour = now.replace(minute=0, second=0, microsecond=0) - timedelta(hours=1)
    path = _snapshot_filename(last_hour)
    if not path.exists():
        print(f"â— æ‰¾ä¸åˆ°ä¸Šå°æ—¶å¿«ç…§ï¼š{path.name}")
        return None
    with gzip.open(path, 'rb') as f:
        data = pickle.load(f)
    print(f"[{now:%F %T}] ğŸ“– snapshot {path.name} loaded")
    return data

def clock_worker(shared_ref):
    """
    æ¯ 30 s æ£€æŸ¥ä¸€æ¬¡æ—¶é—´ï¼š
      - è¿›å…¥ xx:59:00 ~ xx:59:59 æœŸé—´ â†’ ä¿å­˜å¿«ç…§
      - è¿›å…¥ xx:00:00 ~ xx:00:59 æœŸé—´ â†’ è¯»å–ä¸Šå°æ—¶å¿«ç…§
    """
    last_save_hour = None
    last_load_hour = None
    while True:
        now = datetime.utcnow()
        if now.minute == 59 and now.hour != last_save_hour and HOST_IP.find('66.187') != -1:
            save_snapshot(shared_ref)
            last_save_hour = now.hour

        elif now.minute == 0 and now.hour != last_load_hour and HOST_IP.find('66.187') == -1:
            snap = load_last_snapshot()
            # è¿™é‡Œå¯è°ƒç”¨ downstream(snap) åšåˆ†æ / ç”»å›¾ / å†™ DB â€¦
            last_load_hour = now.hour
            return snap

        time.sleep(30)           # åˆ†è¾¨ç‡ 30 ç§’å³å¯



# è·å–èµ„äº§æ€»é¢å¹¶ä¿å­˜
def log_asset():
    total_equity_usd = exchange.fetch_balance('USDT')
    
    # ä¿å­˜åˆ°æ–‡ä»¶ï¼ˆä¿®å¤ï¼šä½¿ç”¨ balance_file_path æ£€æŸ¥å­˜åœ¨æ€§ï¼Œå¹¶å®¹é”™è¯»å–ï¼‰
    if os.path.exists(balance_file_path):
        try:
            with open(balance_file_path, 'r') as f:
                data = json.load(f)
        except Exception:
            data = []
        data.append({'timestamp': time.time(), 'total_equity_usd': total_equity_usd})
    else:
        data = [{'timestamp': time.time(), 'total_equity_usd': total_equity_usd}]
    
    with open(balance_file_path, 'w') as f:
        json.dump(data, f)
    
    return data

# ç»˜åˆ¶èµ„äº§èµ°åŠ¿å›¾
def plot_asset_trend():
    if not os.path.exists(balance_file_path):
        return
    
    with open(balance_file_path, 'r') as f:
        data = json.load(f)
    
    # æå–æ—¶é—´æˆ³å’Œèµ„äº§æ€»é¢
    timestamps = [entry['timestamp'] for entry in data]
    total_equity_usd = [float(entry['total_equity_usd']) for entry in data]
    
    # å°†æ—¶é—´æˆ³è½¬æ¢ä¸ºæ—¥æœŸæ—¶é—´æ ¼å¼
    times = [datetime.utcfromtimestamp(ts) for ts in timestamps]
    
    # é€‰æ‹©æ¯äº”åˆ†é’Ÿä¸€ä¸ªç‚¹
    selected_times = []
    selected_equity = []
    
    # æ¯äº”åˆ†é’Ÿé€‰æ‹©ä¸€ä¸ªç‚¹
    gap = 1
    for i in range(0, len(times), gap):  # 10åˆ†é’Ÿä¸€ä¸ªç‚¹
        selected_times.append(times[i])
        selected_equity.append(total_equity_usd[i])
    
    # å¦‚æœæ•°æ®å°‘äº1000æ¡ï¼Œè¡¥å……æ•°æ®
    while len(selected_equity) < 1000:
        selected_equity.append(selected_equity[-1])
        selected_times.append(selected_times[-1] + timedelta(minutes=5))

    # ç»˜åˆ¶èµ„äº§æ›²çº¿
    plt.figure(figsize=(10, 6))
    plt.plot(selected_times[-300:], selected_equity[-300:], label=f"Trend ({gap} mins")

    plt.xlabel('Date')
    plt.ylabel('Total Pos (USD)')
    plt.title('Trend of my Pos')
    plt.legend()
    
    # æ ¼å¼åŒ–æ—¶é—´æ˜¾ç¤ºä¸ºæ¯å°æ—¶æ ‡è®°
    plt.xticks(rotation=45)
    
    # ä¿å­˜å›¾åƒ
    asset_dir = Path(get_current_dir()) / 'trade_runtime_files'
    asset_dir.mkdir(parents=True, exist_ok=True)
    local_asset = str(asset_dir / 'asset_trend.png')
    plt.savefig(local_asset)
    # åŒæ­¥åˆ°è¿œç«¯ï¼ˆä¿ç•™åŸæœ‰é€»è¾‘ï¼Œåªæ”¹æœ¬åœ°è·¯å¾„ï¼‰
    if HOST_IP.find(SERVER_IP) != -1:
        os.system(f'cp {local_asset} ~/mysite/static/images/')
    else:
        os.system(f'scp {local_asset} root@{SERVER_IP}:/root/mysite/static/images/')
    plt.close()



def check_system_resources():
    """æ£€æŸ¥ç³»ç»Ÿèµ„æºä½¿ç”¨æƒ…å†µï¼Œå¿…è¦æ—¶è§¦å‘æ¸…ç†"""
    process = psutil.Process(os.getpid())

    # å†…å­˜æ£€æŸ¥
    mem_info = process.memory_info()
    if mem_info.rss / (1024 * 1024) > MEMORY_LIMIT_MB:
        print(f"âš ï¸ å†…å­˜ä½¿ç”¨è¶…è¿‡ {MEMORY_LIMIT_MB}MBï¼Œæ‰§è¡Œç´§æ€¥æ¸…ç†")
        gc.collect()

    # CPUæ£€æŸ¥
    if process.cpu_percent(interval=1) > CPU_LIMIT_PERCENT:
        print(f"âš ï¸ CPUä½¿ç”¨ç‡è¶…è¿‡ {CPU_LIMIT_PERCENT}%ï¼Œæš‚åœå¤„ç†")
        time.sleep(10)

# å‡è®¾ time_gap æ˜¯ '1d', '1h', '15m' ç­‰ç­‰
def generate_time_axis(time_gap, length):
    unit_map = {
        '1d': timedelta(days=1),
        '4h': timedelta(hours=4),
        '1h': timedelta(hours=1),
        '15m': timedelta(minutes=15),
        '5m': timedelta(minutes=5),
        '1m': timedelta(minutes=1),
    }
    now = datetime.now()
    step = unit_map.get(time_gap, timedelta(days=1))  # é»˜è®¤æŒ‰å¤©
    return [now - i * step for i in reversed(range(length))]


# @TODO éœ€è¦æ”¹è¿›ä¸‹ï¼Œä¸ç„¶ä»¥åæ•°æ®é‡å¤§äº†ç®€ç›´ç»æœ›

def store_coin_data_if_needed(df, coin, time_gap, base_path=None):
    """
    å­˜å‚¨æ¯ä¸ªå¸ç§çš„å¤„ç†åçš„ DataFrame åˆ°æœ¬åœ° CSVã€‚
    å¦‚æœ CSV å·²å­˜åœ¨ï¼Œåˆ™åˆå¹¶å¹¶å»é‡åå†™å…¥ï¼›å¦åˆ™åˆ›å»ºæ–°æ–‡ä»¶ã€‚
    """
    # å°†é»˜è®¤è·¯å¾„æ”¹ä¸ºå½“å‰è„šæœ¬ç›®å½•ä¸‹çš„å­ç›®å½•ï¼ˆæŒ‰è¦æ±‚ä½¿ç”¨ get_current_dir() + '/' + å½¢å¼ï¼‰
    if base_path is None:
        base_path = get_current_dir() + '/' + 'data/coin_change_data'

    os.makedirs(base_path, exist_ok=True)
    file_path = os.path.join(base_path, f"{coin.upper()}_{time_gap}.csv")

    df = df.copy()
    df['trade_date'] = pd.to_datetime(df['trade_date'])

    if os.path.exists(file_path):
        try:
            existing_df = pd.read_csv(file_path, parse_dates=['trade_date'])
            combined_df = pd.concat([existing_df, df], ignore_index=True)
            combined_df.drop_duplicates(subset='trade_date', inplace=True)
            combined_df.sort_values('trade_date', inplace=True)
            combined_df.to_csv(file_path, index=False)
            print(f"\râœ… å·²æ›´æ–°å¹¶ä¿å­˜ {coin.upper()} æ•°æ®åˆ° {file_path}ï¼Œå…± {len(combined_df)} æ¡è®°å½•ã€‚", end='')
        except Exception as e:
            print(f"âŒ è¯»å–æˆ–åˆå¹¶ {file_path} å¤±è´¥ï¼š{e}")
    else:
        df.sort_values('trade_date', inplace=True)
        df.to_csv(file_path, index=False)
        print(f"ğŸ“„ åˆæ¬¡ä¿å­˜ {coin.upper()} æ•°æ®åˆ° {file_path}ï¼Œå…± {len(df)} æ¡è®°å½•ã€‚")


warnings.filterwarnings("ignore")


def calculate_daily_returns(data):
    """è®¡ç®—æ¯æ—¥æ¶¨è·Œå¹…ï¼Œç¡®ä¿æ•°æ®æŒ‰æ—¶é—´å‡åºå¤„ç†ï¼Œå¹¶é€†è½¬ç´¢å¼•"""
    data['trade_date'] = pd.to_datetime(data['trade_date'], unit='ms')
    data.sort_values('trade_date', ascending=True, inplace=True)  # ç¡®ä¿æ•°æ®æŒ‰æ—¥æœŸå‡åºæ’åˆ—
    data.reset_index(drop=True, inplace=True)  # é‡ç½®ç´¢å¼•ï¼Œä¸¢å¼ƒæ—§ç´¢å¼•
    data['close'] = pd.to_numeric(data['close'], errors='coerce')  # ç¡®ä¿closeåˆ—ä¸ºæ•°å€¼ç±»å‹
    data['high'] = pd.to_numeric(data['high'], errors='coerce')  # ç¡®ä¿closeåˆ—ä¸ºæ•°å€¼ç±»å‹
    data['low'] = pd.to_numeric(data['low'], errors='coerce')  # ç¡®ä¿closeåˆ—ä¸ºæ•°å€¼ç±»å‹
    data['open'] = pd.to_numeric(data['open'], errors='coerce')  # ç¡®ä¿closeåˆ—ä¸ºæ•°å€¼ç±»å‹
    data['vol'] = pd.to_numeric(data['vol'], errors='coerce')  # ç¡®ä¿closeåˆ—ä¸ºæ•°å€¼ç±»å‹.
    data['vol1'] = pd.to_numeric(data['vol1'], errors='coerce')  # ç¡®ä¿closeåˆ—ä¸ºæ•°å€¼ç±»å‹
    data.dropna(subset=['close'], inplace=True)  # ç§»é™¤ä»»ä½•å› è½¬æ¢å¤±è´¥è€Œå˜ä¸ºNaNçš„è¡Œ
    data['daily_return'] = data['close'].pct_change() * 100
    data['daily_return_vol1'] = data['vol1'].pct_change() * 100
    return data


def fetch_and_process(coin, timeframe='5m'):
    """è·å–æ•°æ®å¹¶å¤„ç†"""
    try:
        data = shared_data[timeframe][coin]
        df = calculate_daily_returns(data)
        return df
    except Exception as e:
        print('aaa???', e, timeframe, coin, len(shared_data))
        time.sleep(3)
        return None


def fetch_loop(coins: list, tf: str, interval_sec: int):
    while True:
        for coin in coins:
            if shared_data.get(tf, None) is not None:
                if shared_data.get(tf).get(coin) is not None:
                    time.sleep(interval_sec)
                else:
                    time.sleep(0.1)
            else:
                time.sleep(0.1)
            symbol = f"{coin.upper()}-USDT-SWAP"
            try:
                # with lock_for_apis:
                    # data, err = exchange.get_kline(tf, KLINE_LENGTH, symbol)
                data, err = exchange.get_kline(tf, KLINE_LENGTH, symbol)
                if err is not None:
                    time.sleep(5)
                    print(f"ğŸ˜” fetch {symbol} {tf} err:", err)
                    continue
                if tf == '1d':
                    data = pad_dataframe_to_length_fast(data, KLINE_LENGTH)
                with lock:
                    if coin in shared_data[tf]:
                        del shared_data[tf][coin]
                    shared_data[tf][coin] = data
            except Exception as e:
                print(f"âŒ api fetch {symbol} {tf} err:", e)



def correlation_heatmap(coins, time_gap='5m', method='spearman',
                        btc_ticker='btc', figsize_base=0.4,
                        annot_threshold=30):
    """
    coins           : list[str]  æ‰€æœ‰å¸ç§ï¼ˆå« btcï¼‰
    btc_ticker      : str        è°å½“å…¬å…±å› å­
    figsize_base    : float      æ¯ä¸ªå¸å®½é«˜å€ç‡ï¼›0.4 â†’ 40px
    annot_threshold : int        å½“å¸ç§å¤šäºæ­¤é˜ˆå€¼æ—¶ä¸å†™æ•°å­—
    """
    # ---------- 1. ä¸‹è½½ + å–æ—¥æ”¶ç›Š -------------------------
    dfs = {}
    for c in coins:
        df = fetch_and_process(c, time_gap)
        if df is not None:
            dfs[c] = df.set_index('trade_date')['daily_return']
    if len(dfs) < 3 or btc_ticker not in dfs:
        print("å¯ç”¨å¸ç§ä¸è¶³ï¼Œæˆ–ç¼º btc æ•°æ®")
        return

    # ---------- 2. å¯¹é½ç´¢å¼• & ç»„ DataFrame ---------------
    ret_df = pd.concat(dfs, axis=1).dropna(how='any')     # shape: (T, N)

    # ---------- 3. å» BTC Î² æˆåˆ† --------------------------
    y = ret_df[btc_ticker]
    var_btc = y.var()
    betas = ret_df.apply(lambda col: col.cov(y) / var_btc if col.name != btc_ticker else 1)
    # demean
    adj_df = ret_df.subtract(y * betas, axis=0)

    # ---------- 4. è®¡ç®—ç›¸å…³çŸ©é˜µ ---------------------------
    corr_mat = adj_df.corr(method=method).round(2)

    # ---------- 5. ç”»çƒ­åŠ›å›¾ ------------------------------
    n = len(corr_mat)
    figsize = (figsize_base * n, figsize_base * n)
    show_annot = n <= annot_threshold

    mask = np.triu(np.ones_like(corr_mat, dtype=bool))
    plt.figure(figsize=figsize)
    sns.set(style='white')
    sns.heatmap(corr_mat, mask=mask, cmap='coolwarm', vmin=-1, vmax=1,
                square=True, annot=show_annot, fmt=".2f",
                annot_kws={"size": max(6, int(240/n))},
                linewidths=.5, cbar_kws={"shrink": .8})

    plt.title(f"{method.capitalize()} Corr (after BTC-Î²)  â€“ {time_gap}", fontsize=max(8, int(240/n)))
    plt.tight_layout()
    out_dir = Path(get_current_dir()) / 'chart_for_group'
    out_dir.mkdir(parents=True, exist_ok=True)
    out = str(out_dir / f'heatmap_{time_gap}.png')
    plt.savefig(out, dpi=150)
    plt.close(); gc.collect()
    print(f"âœ… ç›¸å…³çƒ­å›¾å·²ä¿å­˜ â†’ {out}")

def find_levels(series: pd.Series,
                win: int = 20,
                tol: float = 0.05,
                min_hits: int = 2):
    """
    è¿”å› list[dict] ï¼š{'value': æ°´å¹³ä»·, 'first': idx, 'last': idx, 'hits': n}
    æ”¯æ’‘/å‹åŠ›ä¾ä¸­ä½æ•°åˆ†å‰²
    """
    half, full = win, 2 * win + 1
    s = series.dropna()

    # å±€éƒ¨æå€¼
    roll_max = s.rolling(full, center=True, min_periods=1).max()
    roll_min = s.rolling(full, center=True, min_periods=1).min()
    extrema  = pd.concat([
        pd.Series(s[s == roll_max], name='max'),
        pd.Series(s[s == roll_min], name='min')
    ]).sort_index()

    levels = []
    for ts, val in extrema.items():
        i = series.index.get_loc(ts)          # æ•°å€¼ç´¢å¼•
        for lvl in levels:
            if abs(val - lvl['value']) <= tol * lvl['value']:
                lvl['hits']  += 1
                lvl['value'] = (lvl['value'] * (lvl['hits']-1) + val) / lvl['hits']
                lvl['first'] = min(lvl['first'], i)
                lvl['last']  = max(lvl['last'],  i)
                break
        else:
            levels.append({'value': val, 'hits': 1, 'first': i, 'last': i})

    levels = [l for l in levels if l['hits'] >= min_hits]

    med = s.median()
    supports    = [l for l in levels if l['value'] <  med]
    resistances = [l for l in levels if l['value'] >= med]
    return supports, resistances


def draw_segment_levels(ax, levels, color, label, date_index, extend=10):
    """
    levels : list[dict] from find_levels
    date_index : å…¨æ—¶é—´è½´çš„ DatetimeIndex / list
    """
    for i, lvl in enumerate(levels, 1):
        start = max(0, lvl['first'] - extend)
        end   = min(len(date_index)-1, lvl['last'] + extend)
        xs = date_index[start:end+1]
        ys = [lvl['value']] * (end - start + 1)
        ax.plot(xs, ys, color=color, lw=3, ls=(0, (6, 4)),
                label=f'{label} #{i}' if i == 1 else None, zorder=4)

def draw_allcoin_trend(time_gap, coins):
    # â‘  å– close & vol Series å¹¶ inner-join ------------------------------------------------
    close_df = pd.concat(
        {c: fetch_and_process(c, time_gap).set_index('trade_date')['close']
         for c in coins}, axis=1, join='inner'
    )
    if close_df.shape[1] < 2:
        print(f"[{time_gap}] å¯ç”¨å¸ä¸è¶³")
        return

    vol_df = pd.concat(
        {c: fetch_and_process(c, time_gap).set_index('trade_date')['vol']
         for c in coins}, axis=1, join='inner'
    ).reindex(close_df.index)           # ä¿è¯ç´¢å¼•ä¸€è‡´

    # â‘¡ ä»·æ ¼ %Change
    trend_df = close_df.div(close_df.iloc[0]).sub(1).mul(100)

    # â‘¢ æ€»æˆäº¤é‡å½’ä¸€åŒ–
    total_vol_norm = vol_df.sum(axis=1) / vol_df.sum(axis=1).iloc[0] * 100

    # â‘£ è®¡ç®—ma10å’Œå¸ƒæ—å¸¦
    ma10_df = close_df.rolling(10).mean()
    ma5_df = close_df.rolling(5).mean()
    bollinger_lower = close_df.rolling(20).mean() - 2 * close_df.rolling(20).std()

    # â‘¤ ç»˜å›¾ -------------------------------------------------------------------------------
    fig, (ax_price, ax_vol) = plt.subplots(2,1, sharex=True, figsize=(20,14),
                                           gridspec_kw={'height_ratios':[3,1]})

    colors   = sns.color_palette("husl", len(trend_df.columns))
    ls_cycle = itertools.cycle(['-','--','-.',':'])

    ma10_status = []
    boll_status = []
    for col, colr in zip(trend_df, colors):
        
        is_best = col.lower() in best_performance_coins      # â† ä½ çš„æœ€ä½³åˆ—è¡¨

        lw      = 2 if is_best else 1
        alpha   = 0.9 if is_best else 0.75
        zorder  = 2   if is_best else 1
        ls = next(ls_cycle)
        if is_best:
            ls == '--'
        else:
            ls = next(ls_cycle)

        ax_price.plot(trend_df.index, trend_df[col],
                    color=colr, ls=next(ls_cycle),
                  lw=lw, alpha=alpha, zorder=zorder,)
        ax_price.text(trend_df.index[-1], trend_df[col].iloc[-1],
                        col.upper() + ('â˜…' if is_best else ''),
                        color=colr,
                        fontsize=12 if is_best else 9,
                        fontweight='bold' if is_best else 'normal',
                        ha='left', va='center')

        # æ ‡è®°ç‚¹æ”¶é›†
        up_ma10_x, up_ma10_y = [], []
        down_ma10_x, down_ma10_y = [], []
        up_boll_x, up_boll_y = [], []
        down_boll_x, down_boll_y = [], []

        for i in range(1, len(close_df)):
            prev_val = ma5_df[col].iloc[i-1]
            cur_val = ma5_df[col].iloc[i]
            prev_ma10 = ma10_df[col].iloc[i-1]
            cur_ma10 = ma10_df[col].iloc[i]
            prev_boll = bollinger_lower[col].iloc[i-1]
            cur_boll = bollinger_lower[col].iloc[i]

            idx = trend_df.index[i]

            # ä¸Šç©¿ma10
            if prev_val < prev_ma10 and cur_val >= cur_ma10:
                up_ma10_x.append(idx)
                up_ma10_y.append(trend_df[col].iloc[i])
            # ä¸‹ç©¿ma10
            if prev_val > prev_ma10 and cur_val <= cur_ma10:
                down_ma10_x.append(idx)
                down_ma10_y.append(trend_df[col].iloc[i])
            # ä¸Šç©¿å¸ƒæ—å¸¦
            if prev_val < prev_boll and cur_val >= cur_boll:
                up_boll_x.append(idx)
                up_boll_y.append(trend_df[col].iloc[i])
            # ä¸‹ç©¿å¸ƒæ—å¸¦
            if prev_val > prev_boll and cur_val <= cur_boll:
                down_boll_x.append(idx)
                down_boll_y.append(trend_df[col].iloc[i])

        # æ‰¹é‡ç”»ç‚¹
        ax_price.scatter(up_ma10_x, up_ma10_y, marker='^', color='red', s=20, zorder=5, label=None)
        ax_price.scatter(down_ma10_x, down_ma10_y, marker='v', color='blue', s=20, zorder=5, label=None)
        ax_price.scatter(up_boll_x, up_boll_y, marker='*', color='red', s=20, zorder=5, label=None)
        ax_price.scatter(down_boll_x, down_boll_y, marker='o', color='blue', s=20, zorder=5, label=None)

        # ç»Ÿè®¡å½“å‰çŠ¶æ€
        cur_val = close_df[col].iloc[-1]
        cur_ma10 = ma10_df[col].iloc[-1]
        cur_boll = bollinger_lower[col].iloc[-1]
        ma10_status.append(cur_val > cur_ma10)
        boll_status.append(cur_val > cur_boll)

    # BTC ç²—çº¿ç½®é¡¶ï¼ˆè‹¥åœ¨åˆ—è¡¨ä¸­ï¼‰
    if 'btc' in trend_df.columns:
        ax_price.plot(trend_df.index, trend_df['btc'], ls='--',
                      color='#CC5500', lw=3, )

    n_above_ma10 = sum(ma10_status)
    n_below_ma10 = len(ma10_status) - n_above_ma10
    n_above_boll = sum(boll_status)
    n_below_boll = len(boll_status) - n_above_boll

    stat_text = f"> MA10: {n_above_ma10}  < MA10: {n_below_ma10}  |  > Boll: {n_above_boll}  < Boll: {n_below_boll}"
    ax_price.text(0.01, 0.99, stat_text, transform=ax_price.transAxes, fontsize=14, color='black', va='top', ha='left', bbox=dict(facecolor='white', alpha=0.7))

    ax_price.grid(alpha=.3)
    ax_price.set_title(f'All-Coin %Change â€” {time_gap.upper()}')
    ax_price.set_ylabel('% change')
    ax_price.legend(fontsize=8)

    ax_vol.plot(trend_df.index, total_vol_norm, color='black', lw=1.8)
    ax_vol.fill_between(trend_df.index, total_vol_norm,
                        color='steelblue', alpha=.25)
    ax_vol.set_title('Aggregate Volume (norm=100)')
    ax_vol.set_ylabel('Vol index')
    ax_vol.grid(alpha=.3)

    plt.tight_layout()


    out_dir = Path(get_current_dir()) / 'chart_for_group'
    out_dir.mkdir(parents=True, exist_ok=True)
    out = str(out_dir / f'allcoin_trend_{time_gap if ("m" in time_gap) else time_gap.upper()}.png')
    plt.tight_layout()
    plt.savefig(out, dpi=150)
    plt.close()
    print(f"ğŸ“ˆ ä¿å­˜ {out}")




# ---------------------- æ ¸å¿ƒå‡½æ•° --------------------------------------
def multi_tf_ma_bBands_signal(df_1m, df_15m, df_1h, df_4h, df_1d,
                              symbol='ETH'):
    frames = {
        '1m' : df_1m.copy(),
        '15m': df_15m.copy(),
        '1h' : df_1h.copy(),
        '4h' : df_4h.copy(),
        '1d' : df_1d.copy()
    }

    # 1âƒ£ è®¡ç®— MA5/MA10/BollMid20 æœ€æ–°å€¼
    state = {}   # å‘¨æœŸ -> 'bull' / 'bear' / 'mix'
    for tf, df in frames.items():
        c = df['close']
        ma5  = c.rolling(5).mean().iloc[-1]
        ma10 = c.rolling(10).mean().iloc[-1]
        mid  = c.rolling(20).mean().iloc[-1]

        if ma5 > ma10 > mid:
            state[tf] = 'bull'
        elif ma5 < ma10 < mid:
            state[tf] = 'bear'
        else:
            state[tf] = 'mix'

    # 2âƒ£ æ£€æŸ¥é«˜å‘¨æœŸä¸€è‡´æ€§ï¼ˆ15m/1h/4h/1dï¼‰
    high_tfs = ['15m','1h','4h','1d']
    high_states = [state[t] for t in high_tfs]
    if len(set(high_states)) == 1 and high_states[0] in ('bull','bear'):
        mode = high_states[0]   # å…¨ä¸€è‡´
    else:
        print(f"âŒ {symbol} å„å‘¨æœŸä¸ä¸€è‡´ â†’", state)
        return

    # 3âƒ£ åœ¨ 1m æŸ¥æ‰¾è¿›å…¥/é€€å‡º
    df = frames['1m']
    close = df['close']
    ma5  = close.rolling(5).mean()
    ma10 = close.rolling(10).mean()
    mid  = close.rolling(20).mean()

    if mode == 'bull':
        mask = (ma5 > ma10) & (ma10 > mid)
    else:  # bear
        mask = (ma5 < ma10) & (ma10 < mid)

    # è¿›å…¥ / é€€å‡º ç´¢å¼•
    m = mask.values
    enter = np.where((m[1:] == 1) & (m[:-1] == 0))[0] + 1
    exit_ = np.where((m[1:] == 0) & (m[:-1] == 1))[0] + 1

    # 4âƒ£ ç»˜åˆ¶ 1m èœ¡çƒ› + MA & é˜´å½± + æ ‡è®°
    df_plot = df.dropna().copy()
    df_plot['ma5'] = ma5
    df_plot['ma10'] = ma10
    df_plot = df_plot.iloc[19:]              # ä¿éšœ MA20 å®Œæ•´

    fig, axes = mpf.plot(
        df_plot, type='candle', style='charles',
        mav=(5, 10), returnfig=True,
        figsize=(14, 8),
        title=f'{symbol} 1m â€” {mode.upper()} (MA5/MA10/BBmid)'
    )
    ax = axes[0]

    x = np.arange(len(df_plot))
    ma5_v, ma10_v = df_plot['ma5'].values, df_plot['ma10'].values

    # é˜´å½±
    ax.fill_between(x, ma5_v, ma10_v, where=mask.iloc[-len(df_plot):].values,
                    color='orangered' if mode=='bull' else 'deepskyblue',
                    alpha=.15, interpolate=True)

    # æ ‡è®°
    ax.scatter(x[enter], df_plot['close'].iloc[enter],
               marker='^', color='green', s=50, zorder=6, label='Entry')
    ax.scatter(x[exit_], df_plot['close'].iloc[exit_],
               marker='v', color='red',   s=50, zorder=6, label='Exit')

    ax.legend(fontsize=8)
    plt.tight_layout()

    out_dir = Path(get_current_dir()) / 'chart_for_group' / 'good_coins'
    out_dir.mkdir(parents=True, exist_ok=True)
    out = str(out_dir / f'{symbol.lower()}_multi_tf_signal_{int(time.time())}.png')

    plt.savefig(out, dpi=150)
    plt.close()
    print("ğŸ“ˆ ğŸ“ˆ ğŸ“ˆ å·²ä¿å­˜  ğŸ“ˆ  ğŸ“ˆ ", out)


def factor_strength_ranking(
    data_frames: dict = None,
    lookback: int = 60,
    w_mom: float = 0.4,
    w_slope: float = 0.4,
    w_up: float = 0.2,
):
    """
    ä»…åŸºäº K çº¿èµ°åŠ¿å¼ºå¼±æ‰“åˆ†ï¼šåŠ¨é‡ + çº¿æ€§è¶‹åŠ¿æ–œç‡ + ä¸Šæ¶¨é¢‘ç‡

    Parameters
    ----------
    data_frames : dict[str, pd.DataFrame]
        {"btc": df_btc, ...}ï¼›æ¯ä¸ª df è‡³å°‘å« 'close', 'open'
    lookback : int, default 60
        è®¡ç®—çª—å£ï¼ˆæ ¹æ•°ï¼‰
    w_mom, w_slope, w_up : float
        ä¸‰ä¸ªè§’åº¦çš„æƒé‡ï¼Œå’Œä¸é™äº 1

    Returns
    -------
    score  : ç»¼åˆå¾—åˆ†ï¼ˆè¶Šå¤§è¶Šå¼ºï¼‰
    ranks  : 1 è¡¨ç¤ºæœ€å¼º
    weight : ä»…å¯¹æ­£å¾—åˆ†å½’ä¸€åçš„æƒé‡
    """
    scores = {}
    for sym, df in data_frames.items():
        if len(df) < lookback or "close" not in df.columns or "open" not in df.columns:
            continue

        closes = df["close"].iloc[-lookback:].to_numpy()
        opens  = df["open"].iloc[-lookback:].to_numpy()

        # 1) åŒºé—´åŠ¨é‡
        mom = closes[-1] / closes[0] - 1

        # 2) çº¿æ€§è¶‹åŠ¿æ–œç‡ï¼ˆæœ€å°äºŒä¹˜ï¼‰
        y = closes
        x = np.arange(len(y))
        # [slope, intercept] from lstsq( X @ beta = y )
        slope, _ = lstsq(np.column_stack([x, np.ones_like(x)]), y, rcond=None)[0]
        # ä¸ºå¯æ¯”æ€§è½¬æˆâ€œæ¯æ ¹ç™¾åˆ†æ¯”æ–œç‡â€
        slope_pct = slope / closes[0]

        # 3) ä¸Šæ¶¨é¢‘ç‡
        up_freq = np.mean(closes > opens)  # å æ¯” (0,1)

        # ç»¼åˆå¾—åˆ†
        score = w_mom * mom + w_slope * slope_pct + w_up * up_freq
        scores[sym.upper()] = score

    score = pd.Series(scores).sort_values(ascending=False)
    ranks = score.rank(method="dense", ascending=False).astype(int)

    pos = score.clip(lower=0)
    weight = pos / pos.sum() if pos.sum() > 0 else pos

    return score, ranks, weight


def market_strength_index(
    data_frames: dict,
    lookback: int = 60,
    w_mom: float = 0.5,   # ä¸‰å› å­æƒé‡ï¼Œå¯æŒ‰éœ€è°ƒæ•´
    w_slope: float = 0.3,
    w_up: float = 0.2,
) -> float:
    """
    è®¡ç®—æ•´ä¸ªå¸å¸‚çš„ä¸€ç»´â€œå¼ºå¼±æŒ‡æ•°â€ã€‚

    Parameters
    ----------
    data_frames : dict[str, pd.DataFrame]
        {"btc": df_btc, "eth": df_eth, ...}ï¼Œæ¯ä¸ª df è‡³å°‘å« 'close', 'open'
    lookback : int, default 60
        æœ€è¿‘å¤šå°‘æ ¹ K çº¿ä½œä¸ºè¯„ä¼°çª—å£
    w_mom, w_slope, w_up : float
        M/S/U ä¸‰å› å­çš„ç»„åˆæƒé‡ï¼ˆå’Œä¸å¿… =1ï¼‰

    Returns
    -------
    idx : float
        å¼ºå¼±ç›¸å¯¹å€¼ï¼›>0 => æ•´ä½“å¤šå¤´å ä¼˜ï¼Œ<0 => ç©ºå¤´å ä¼˜
    """
    m_list, s_list, u_list = [], [], []

    for df in data_frames.values():
        if len(df) < lookback or "close" not in df.columns or "open" not in df.columns:
            continue

        closes = df["close"].iloc[-lookback:].to_numpy()
        opens  = df["open"].iloc[-lookback:].to_numpy()

        # 1) åŒºé—´åŠ¨é‡ M
        mom = closes[-1] / closes[0] - 1
        m_list.append(mom)

        # 2) çº¿æ€§è¶‹åŠ¿æ–œç‡ Sï¼ˆè½¬ä¸ºç™¾åˆ†æ¯”ï¼‰
        x = np.arange(lookback)
        slope, _ = lstsq(np.column_stack([x, np.ones_like(x)]), closes, rcond=None)[0]
        slope_pct = slope / closes[0]
        s_list.append(slope_pct)

        # 3) ä¸Šæ¶¨é¢‘ç‡ U
        up_freq = np.mean(closes > opens)   # 0â€“1 ä¹‹é—´
        u_list.append(up_freq)

    if not m_list:
        return 0.0   # æ²¡æœ‰å¯ç”¨æ•°æ®

    # æ‰€æœ‰å¸çš„å› å­å‡å€¼
    m_avg = np.mean(m_list)
    s_avg = np.mean(s_list)
    u_avg = np.mean(u_list)

    # ç»¼åˆæˆå•ä¸€æŒ‡æ•°
    idx = w_mom * m_avg + w_slope * s_avg + w_up * (u_avg - 0.5)  # ä¸Šæ¶¨é¢‘ç‡ä¸­å¿ƒåŒ–

    return float(idx)

def cluster_kline_graph(
    data_frames: dict= None,
    lookback:   int   = 60,      # å–æœ€è¿‘å¤šå°‘æ ¹æ—¥çº¿
    n_clusters: int   = 4,       # æŒ‡å®šç°‡æ•°
    scale:      bool  = True,    # æ˜¯å¦æ ‡å‡†åŒ–æ¯ä¸ªæ—¶é—´æ­¥çš„ç‰¹å¾
) -> dict:
    """
    æ ¹æ®æ—¥çº¿ K çº¿ç›¸ä¼¼æ€§ï¼ŒæŠŠå¤šå¸ç§åˆ†æˆ n_clusters ä¸ªç°‡ï¼ˆå›¾èšç±» / Spectralï¼‰ã€‚

    Parameters
    ----------
    data_frames : dict[str, pd.DataFrame]
        {"btc": df_btc, ...}ï¼Œæ¯ä¸ª df è‡³å°‘å« ['open','high','low','close']
    lookback : int
        å‚ä¸èšç±»çš„æœ€è¿‘æ—¥çº¿æ ¹æ•°
    n_clusters : int
        ç›®æ ‡ç°‡ä¸ªæ•°
    scale : bool
        True åˆ™å¯¹æ‰€æœ‰æ—¶é—´æ­¥ç‰¹å¾åšæ ‡å‡†åŒ–ï¼Œæœ‰åŠ©äºè·ç¦»åº¦é‡

    Returns
    -------
    clusters : dict[int, list[str]]
        {ç°‡ç¼–å·: [symbol, â€¦]}ï¼Œç¼–å·ä» 0 å¼€å§‹
    """
    symbols, embeds = [], []

    # ---------- 1. ç”Ÿæˆæ¯ä¸ªå¸çš„ K çº¿åµŒå…¥ ----------
    for sym, df in data_frames.items():
        if len(df) < lookback or not {'open','high','low','close'}.issubset(df.columns):
            continue

        # æœ€è¿‘ lookback æ ¹æ—¥çº¿
        slice_df = df.iloc[-lookback:]

        # â‘  ä»·æ ¼åŠ¨é‡ â‘¡ æŒ¯å¹…
        mom     = (slice_df['close'] - slice_df['open']) / slice_df['open']
        amp     = (slice_df['high']  - slice_df['low'])  / slice_df['open']

        # æ¯æ ¹æ—¥çº¿ â†’ ä¸¤ç»´ç‰¹å¾ï¼›å±•å¹³ä¸º (2*lookback,) å‘é‡
        embed_vec = np.vstack([mom, amp]).T.flatten()
        embeds.append(embed_vec)
        symbols.append(sym.upper())

    if len(embeds) < n_clusters:
        raise ValueError("å¯ç”¨å¸ç§ä¸è¶³ä»¥å½¢æˆæŒ‡å®šç°‡æ•°")

    X = np.vstack(embeds)                       # shape = (N_coins, 2*lookback)

    # ---------- 2. ï¼ˆå¯é€‰ï¼‰æ ‡å‡†åŒ– ----------
    if scale:
        X = StandardScaler().fit_transform(X)

    # ---------- 3. ç›¸ä¼¼åº¦çŸ©é˜µï¼ˆä½™å¼¦ï¼‰ ----------
    affinity = cosine_similarity(X)            # å€¼åŸŸ [-1,1]

    # ---------- 4. å›¾èšç±» ----------
    model = SpectralClustering(
        n_clusters   = n_clusters,
        affinity     = 'precomputed',
        assign_labels= 'kmeans',
        random_state = 42,
    )
    labels = model.fit_predict(affinity)       # ndarray, shape = (N_coins,)

    # ---------- 5. ç»„ç»‡è¾“å‡º ----------
    clusters = {}
    for sym, lab in zip(symbols, labels):
        clusters.setdefault(int(lab), []).append(sym)

    return clusters



def main1(top10_coins=['btc', 'eth', 'xrp', 'bnb', 'sol', 'ada', 'doge', 'trx', 'ltc', 'shib'], prex='', time_gap='5m', good_group = [], all_rate={}, bad_coins=[]):
    # top10_coins = ['btc', 'eth','xrp', 'bnb', 'sol', 'ada', 'doge', 'trx', 'ltc', 'shib', 'link', 'dot', 'om', 'apt',
    #      'uni', 'hbar', 'ton', 'sui', 'avax', 'fil', 'ip', 'gala', 'sand']
    if len(good_group) == 0:
        try:
            print(get_current_dir() + '/' + 'good_group_plot.txt')
            with open(get_current_dir() + '/' + 'good_group_plot.txt', 'r', encoding='utf8') as f:
                data = f.readlines()
                good_group = data[0].strip().split(',')
                all_rate = [float(x) for x in data[1].strip().split(',')]
                if len(good_group) != len(all_rate):
                    print('TMDä¸å¯¹å•Š')
                    return None
                btc_rate = all_rate[0] / sum(all_rate)
                if len(data) == 3:
                    bad_coins = [x for x  in f.readline().strip().split(',') if x not in good_group]
                else:
                    bad_coins = []
        except Exception as e:
            print('æˆ‘è‰æ‹Ÿå— ä»–ä¹ˆå‡ºä»€ä¹ˆå‚»é€¼é—®é¢˜äº†ï¼Ÿï¼', e)
            good_group = ['btc', 'sol']
            bad_coins = []
    if len(bad_coins) > 0:
        top10_coins = bad_coins
    
    data_frames = {}
    # è·å–å¹¶å¤„ç†æ‰€æœ‰å¸ç§çš„æ•°æ®
    for coin in top10_coins + good_group:
        df = fetch_and_process(coin, time_gap)
        data_frames[coin] = df
    
    market_idx_1 = market_strength_index(data_frame, lookback=30)

    # â‘  ---------- æ„é€ æƒé‡å‘é‡ï¼ˆå½’ä¸€åŒ–åˆ° 1ï¼‰------------------------------
    total = sum(all_rate)
    weights = {c: r / total for c, r in zip(good_group, all_rate)}  # {'btc':0.45, 'doge':0.30, â€¦}
    # â‘¡ ---------- æ‹¼æ¥ good_group çš„æ”¶ç›Šåˆ— -------------------------------
    good_df = pd.concat(
        [data_frames[c]['daily_return'].rename(c)  # åˆ—å=å¸å
         for c in good_group if c in data_frames],
        axis=1
    )

    # â‘¢ ---------- åŠ æƒæ±‚å’Œ ---------------------------------------------
    w_series = pd.Series(weights).reindex(good_df.columns, fill_value=0)  # å¯¹é½åˆ—é¡ºåº
    goodGroup_returns = (good_df.mul(w_series, axis=1)).sum(axis=1)  # è¡Œå‘é‡âˆ™æƒé‡

    # â‘£ ---------- å…¶ä½™é good_group ä»ç„¶è®¡ç®—ç­‰æƒå‡å€¼ --------------------
    average_returns = pd.concat(
        [data_frames[coin]['daily_return']
         for coin in top10_coins if coin not in good_group and coin in data_frames],
        axis=1
    ).mean(axis=1)



    upper_band_name = 'bollinger_upper'
    lower_band_name = 'bollinger_lower'
    column = ['close']
    window = 20
    sma = data_frames['btc'][column].rolling(window=window).mean()
    if upper_band_name not in data_frames['btc'].columns or lower_band_name not in data_frames['btc'].columns:
        std = data_frames['btc'][column].rolling(window=window).std()
        data_frames['btc'][upper_band_name] = sma + (std * 2)
        data_frames['btc'][lower_band_name] = sma - (std * 2)

        # ç¡®ä¿ä¸Šä¸‹è½¨å‰20ä¸ªç©ºå€¼è¢«å¡«å……
        data_frames['btc'][upper_band_name] = data_frames['btc'][upper_band_name].fillna(method='bfill',
                                                                                         limit=window - 1)
        data_frames['btc'][lower_band_name] = data_frames['btc'][lower_band_name].fillna(method='bfill',
                                                                                         limit=window - 1)

    data_frames['btc']['bollinger_middle'] = sma
    # è·å–BTCæ•°æ®æ—¶ä¹Ÿè¿›è¡Œå¡«å……
    btc_upper_bollinger = data_frames['btc'][upper_band_name].fillna(method='bfill', limit=window - 1)
    btc_bollinger_lower = data_frames['btc'][lower_band_name].fillna(method='bfill', limit=window - 1)

    btc_close_price = data_frames['btc']['close']
    btc_high_price = data_frames['btc']['high']
    btc_low_price = data_frames['btc']['low']
    sum_profile = 0
    # Calculate the difference and cumulative sum
    diff_returns = goodGroup_returns - average_returns
    stack_profile = diff_returns.cumsum()

    WINDOW  = 20          # æ»šåŠ¨çª—å£
    N_STD   = 2           # n Ã— æ ‡å‡†å·®

        # rolling mean / std
    stack_mid   = stack_profile.rolling(WINDOW).mean()
    stack_std   = stack_profile.rolling(WINDOW).std()

    stack_upper = stack_mid + N_STD * stack_std
    stack_lower = stack_mid - N_STD * stack_std

    # å¤´éƒ¨ NaN ç”¨å‰å‘å¡«å……ï¼Œç¡®ä¿æ•´æ¡æ›²çº¿è¿è´¯
    stack_mid   = stack_mid.fillna(method='bfill', limit=WINDOW-1)
    stack_upper = stack_upper.fillna(method='bfill', limit=WINDOW-1)
    stack_lower = stack_lower.fillna(method='bfill', limit=WINDOW-1)


    # ----------------- 1. å‚æ•° -----------------------
    lookback = 200
    n_sigma  = 2
    r2_th    = 0.50

    y = stack_profile.iloc[-lookback:].values
    x = np.arange(len(y))

    # â‘  çº¿æ€§æ‹Ÿåˆ (y = aÂ·x + b)
    a, b = np.polyfit(x, y, 1)
    y_pred = a * x + b

    # â‘¡ RÂ²
    ss_res = np.sum((y - y_pred) ** 2)
    ss_tot = np.sum((y - y.mean()) ** 2)
    r2 = 1 - ss_res / ss_tot

    if r2 >= r2_th:
        sigma = np.std(y - y_pred)
        upper = y_pred + n_sigma * sigma
        lower = y_pred - n_sigma * sigma

        idx   = stack_profile.index[-lookback:]
        upper = pd.Series(upper, index=idx)
        lower = pd.Series(lower, index=idx)

    for i in range(len(goodGroup_returns)):
        sum_profile += (float(goodGroup_returns[i]) - float(average_returns[i]))

    reduce_part = goodGroup_returns - average_returns

    date_range = goodGroup_returns.index
    btc_trend = (btc_close_price / btc_close_price[0] - 1) * 100
    high_trend = (btc_high_price / btc_close_price[0] - 1) * 100
    low_trend = (btc_low_price / btc_close_price[0] - 1) * 100
    upper_trend = (btc_upper_bollinger / btc_close_price[0] - 1) * 100
    lower_trend = (btc_bollinger_lower / btc_close_price[0] - 1) * 100


    # â”€â”€ â¶ é«˜ç‚¹ > ä¸Šè½¨ ä¸” æ”¶ç›˜ < ä¸Šè½¨  â†’ "ä¸Šå½±åˆºç ´" -----------------------------
    above_upper = np.where( (high_trend >= upper_trend) & (btc_trend  <  upper_trend))[0]

    # â”€â”€ â· ä½ç‚¹ < ä¸‹è½¨ ä¸” æ”¶ç›˜ > ä¸‹è½¨  â†’ "ä¸‹å½±åˆºç ´" -----------------------------
    below_lower = np.where(  (low_trend  <= lower_trend) &  (btc_trend  >  lower_trend)  )[0]


    stack_above = [stack_profile[i] for i in above_upper]
    stack_below = [stack_profile[i] for i in below_lower]


    
    # ---------------------------------------------------------------
    # 0âƒ£  æ±‡æ€» vol åºåˆ—
    vol_df = pd.concat(
        {c: data_frames[c]['vol'].rename(c) for c in data_frames},
        axis=1
    ).dropna(how='any')

    good_set = set(good_group)

    good_cols  = [c for c in vol_df.columns if c in good_set]          # â† list
    other_cols = [c for c in vol_df.columns if c not in good_set]      # â† list

    # 1âƒ£  ç»„å†…æ±‚å’Œ
    vol_good  = vol_df[good_cols].sum(axis=1)
    vol_other = vol_df[other_cols].sum(axis=1)

    # 2âƒ£  å„è‡ªå½’ä¸€åŒ– 0-1
    norm = lambda s: (s - s.min()) / (s.max() - s.min())
    vol_good_n  = norm(vol_good)
    vol_other_n = norm(vol_other)

    # 3âƒ£  å·®å€¼èµ°åŠ¿
    vol_spread = vol_good_n - vol_other_n


    # â‘  è®¡ç®—å„è‡ªæŒ¯å¹…
    stack_range = stack_profile.max() - stack_profile.min()
    target_range = 0.5 * stack_range            # ç›®æ ‡æŒ¯å¹…

    vol_range = vol_spread.max() - vol_spread.min()
    if vol_range == 0:
        raise ValueError("vol_spread æŒ¯å¹…ä¸º 0ï¼Œæ— æ³•ç¼©æ”¾")

    # â‘¡ çº¿æ€§ç¼©æ”¾ï¼ˆä¿æŒæ­£è´Ÿå· & ä¸­å¿ƒï¼‰
    scale = target_range / vol_range
    vol_spread_scaled = vol_spread * scale

    # â‘¢ å¯é€‰ï¼šè®©é›¶ç‚¹å¯¹é½ stack_profile çš„ä¸­ä½æ•°
    # mid_shift = stack_profile.median() - vol_spread_scaled.median()
    # vol_spread_scaled += mid_shift



    # â”€â”€â”€â”€â”€â”€â”€â”€â”€ æ•°æ®å‡†å¤‡ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    total_vol  = vol_df.sum(axis=1)                # å…¨å¸‚åœºæ€»æˆäº¤é‡
    vol_btc    = vol_df['btc']                     # BTC æˆäº¤é‡
    # â‘¡ æˆäº¤é‡æ  (ax_vol)  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    if time_gap.find('h') != -1:
        # â€”â€” 1) ç¡®ä¿ä¸ºæŒ‰ç›¸åŒç´¢å¼•å¯¹é½çš„ Series â€”â€” 
        sp  = pd.Series(stack_profile, index=date_range)              # stack_profile
        mid = pd.Series(stack_mid,   index=date_range)                # å¸ƒæ—ä¸­è½¨(å‡çº¿)
        ix  = sp.index.intersection(mid.index)
        sp, mid = sp.loc[ix], mid.loc[ix]

        # â€”â€” 2) è®¡ç®—ç©¿è¶Šç‚¹ï¼šå·®å€¼ç¬¦å·å‘ç”Ÿæ”¹å˜ï¼ˆä¸¥æ ¼ç©¿è¿‡ï¼‰â€”â€”
        diff = sp - mid
        s    = np.sign(diff.to_numpy())                               # -1/0/1
        valid = ~np.isnan(s[1:]) & ~np.isnan(s[:-1])
        cross_idx = np.where((s[1:] * s[:-1] < 0) & valid)[0] + 1     # å¯¹åº” sp çš„ç´¢å¼•ä½ç½®

                
    # -------- å¯è§†åŒ–ç¤ºä¾‹ --------------------------------------------


    fig, (ax1, ax_trend, ax_vol) = plt.subplots(
        3, 1, sharex=True, figsize=(16, 11),
        gridspec_kw={'height_ratios': [4, 2, 1]}   # ä¸Š:ä¸­:ä¸‹ = 4:2:1
    )

    # â”€â”€ 2.2 æˆäº¤é‡æŸ±å½¢å›¾ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    ax_vol.bar(date_range, total_vol,
            color='gray', alpha=0.6, width=0.8, label='Total Volume')

    ax_vol.set_ylabel('Total Vol', fontsize=10)
    ax_vol.tick_params(axis='y', labelsize=8)
    ax_vol.grid(alpha=0.2, linestyle='--')
    # ax_vol.legend(loc='upper right', fontsize=8)

    # 2.1 ç°è‰²æŸ±ï¼šæ€»æˆäº¤é‡  (å·¦è½´)
    ax_vol.bar(date_range, total_vol,
            color='gray', alpha=.6, width=0.8, label='Total Volume')
    ax_vol.set_ylabel('Total Vol', color='gray', fontsize=9)
    ax_vol.tick_params(axis='y', labelcolor='gray', labelsize=8)
    ax_vol.grid(alpha=0.25, ls='--')

    # 2.2 å³è½´ï¼švol_spread_scaled + BTC vol
    axv = ax_vol.twinx()


    # æ©™è‰²æŠ˜çº¿ï¼šBTC æˆäº¤é‡ï¼ˆå½’ä¸€åŒ–åˆ°åŒè½´æ–¹ä¾¿å¯¹æ¯”ï¼‰
    btc_scaled = (vol_btc - vol_btc.min()) / (vol_btc.max() - vol_btc.min())
    axv.plot(date_range, btc_scaled,
            color='orange', lw=1.8, label='BTC Volume (norm)')

    axv.set_ylabel('Norm Value', color='purple', fontsize=9)
    axv.tick_params(axis='y', labelcolor='purple', labelsize=8)

    # # â‘¢ å›¾ä¾‹åˆå¹¶ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # h1, l1 = ax_vol.get_legend_handles_labels()
    # h2, l2 = axv.get_legend_handles_labels()
    # ax_vol.legend(h1+h2, l1+l2, loc='upper left', fontsize=8, ncol=2)

    ax1.bar(date_range, reduce_part,
            label='REDUCE Daily Returns in 1d', alpha=0.8, color='purple')

        # ç´«è‰²è™šçº¿ï¼šå½’ä¸€åŒ–å·®å€¼
    ax1.plot(date_range, vol_spread_scaled,
            color='cyan', ls='--', lw=2, label='Vol-Spread (scaled)')


    # â‘  è®¡ç®—æ°´å¹³ä½
    sup_stack, res_stack = find_levels(stack_profile, win=20, tol=0.05, min_hits=2)
    sup_btc,   res_btc   = find_levels(btc_trend,      win=20, tol=0.05, min_hits=2)

    # â‘¡ ç»˜å›¾ï¼šç²—ç‚¹åˆ’çº¿ï¼Œæ”¯æ’‘=ç»¿ï¼Œå‹åŠ›=æ·±è“
    draw_segment_levels(ax1, sup_stack, 'red', 'Stack Support',  date_range)
    draw_segment_levels(ax1, res_stack, 'pink', 'Stack Resist',   date_range)
    draw_segment_levels(ax1, sup_btc,   '#55CC77', 'BTC Support',    date_range)
    draw_segment_levels(ax1, res_btc,   '#3355FF', 'BTC Resist',     date_range)




    # 2.2 å åŠ å¸ƒæ—å¸¦
    ax1.plot(date_range, stack_mid,   color='gray',  lw=1,  ls='--', label='Stack BB Middle')
    ax1.plot(date_range, stack_upper, color='black', lw=1,  ls='-.', label='Stack BB Upper')
    ax1.plot(date_range, stack_lower, color='black', lw=1,  ls='-.', label='Stack BB Lower')
    ax1.fill_between(date_range, stack_lower, stack_upper,  color='gray', alpha=0.08)            # é˜´å½±åŒºå¯é€‰

    eps = 0.05 * (stack_upper - stack_lower)

    # ---------- 1. Bollinger è§¦ç¢°ç‚¹ï¼ˆç»¿ä¸‰è§’ï¼‰------------------------------
    touch_upper = np.where(stack_profile >= stack_upper)[0]
    touch_lower = np.where(stack_profile <= stack_lower)[0]

    # ax1.scatter(date_range[touch_upper], stack_profile.iloc[touch_upper],
    #             marker='v', color='#8fbce6', s=55,
    #             label='Touch BB Upper', zorder=5)
    # ax1.scatter(date_range[touch_lower], stack_profile.iloc[touch_lower],
    #             marker='^', color='#1f77b4', s=55,
    #             label='Touch BB Lower', zorder=5)

    # ---------- Bollinger è§¦ç¢° ----------
    ax1.scatter(date_range[touch_upper], stack_profile.iloc[touch_upper],#  * 1.0033,
                marker='v', color='#00E5FF', edgecolors='black', alpha=0.75,
                linewidths=.4, s=70, label='STACK Touch BB Upper', zorder=5)

    ax1.scatter(date_range[touch_lower], stack_profile.iloc[touch_lower],# * 0.9966,
                marker='^', color='#0066FF', edgecolors='black', alpha=0.75,
                linewidths=.4, s=70, label='STACK Touch BB Lower', zorder=5)



    if r2 >= r2_th:
        ax1.plot(idx, upper,  ls='--', color='red',  lw=1, label='LR Channel Upper')
        ax1.plot(idx, lower,  ls='--', color='red',  lw=1, label='LR Channel Lower')
        # ax1.fill_between(idx, lower, upper, color='green', alpha=0.075)

         # 2.1 ä¿è¯ channel ä¸Šä¸‹è½¨æ‰©å±•åˆ°å®Œæ•´ç´¢å¼•ï¼ˆéé€šé“åŒº NaNï¼‰
        upper_full = pd.Series(index=stack_profile.index, dtype=float)
        lower_full = pd.Series(index=stack_profile.index, dtype=float)
        upper_full.loc[idx] = upper
        lower_full.loc[idx] = lower

        # 2.2 å–å‰åå·®åˆ†åˆ¤æ–­"ç©¿ç ´"
        prev = stack_profile.shift(1)
        up_cross = (prev < upper_full) & (stack_profile > upper_full)
        down_cross = (prev > lower_full) & (stack_profile < lower_full)

        # 2.3 æ ‡è®°
        # ax1.scatter(stack_profile.index[up_cross],
        #             stack_profile[up_cross],
        #             marker='v', color='#ffbb78', s=60,
        #             label='Break Channel â†‘', zorder=6)

        # ax1.scatter(stack_profile.index[down_cross],
        #             stack_profile[down_cross],
        #             marker='^', color='#ff7f0e', s=60,
        #             label='Break Channel â†“', zorder=6)
        # ---------- é€šé“ç©¿ç ´ ----------
        ax1.scatter(stack_profile.index[up_cross], stack_profile[up_cross],# * 1.01,
                    marker='v', color='#FFA200', edgecolors='black',  alpha=0.75,
                    linewidths=.4, s=80, label='Touch UP Channel â†‘', zorder=6)

        ax1.scatter(stack_profile.index[down_cross], stack_profile[down_cross],#  * 0.99,
                    marker='^', color='#FF2400', edgecolors='black',  alpha=0.75,
                    linewidths=.4, s=80, label='Touch LOW Channel â†“', zorder=6)


    ax1.plot(date_range, btc_trend,
             label='BTC/USDT Trend', color='orange')
    ax1.plot(date_range, upper_trend,
             label='upper bollinger', color='black', alpha=0.6)
    ax1.plot(date_range, lower_trend,
             label='lower bollinger', color='black', alpha=0.6)
    
    # ---------- 2. å…¶å®ƒå¸ï¼ˆå«ç¼©æ”¾å BTCï¼‰-------------------------------
    for coin, df in data_frames.items():
        scaled = (df['close'] / df['close'].iloc[0] - 1) * 100

        if coin == 'btc':
            # ç¼©æ”¾å BTC : æ·±æ©˜ç²—è™šçº¿
            ax_trend.plot(date_range, scaled,
                    color='#CC5500', lw=2.5, ls='--')
        else:
            ax_trend.plot(date_range, scaled,
                    color=next(color_iter),
                    ls=next(ls_iter),
                    lw=1.0, alpha=.5)        # label çœç•¥é¿å…å›¾ä¾‹è¿‡é•¿


    # -------- ç¾åŒ– trend é¢æ¿ -------------------------------------------
    ax_trend.set_ylabel('% change')
    ax_trend.grid(alpha=.3)

    # ax1.fill_between(date_range, lower_trend, upper_trend,  color='red', alpha=0.05)            # é˜´å½±åŒºå¯é€‰

    ax1.scatter(date_range[above_upper], btc_trend[above_upper],
                marker='*', color='red', label='BTC > Upper Bollinger',
                zorder=2, alpha=0.75)
    ax1.scatter(date_range[below_lower], btc_trend[below_lower],
                marker='.', color='blue', label='BTC < Lower Bollinger',
                zorder=2, alpha=0.75)
    # ax1.scatter(date_range[above_upper], stack_above,
    #             color='#2ca02c', marker='v', label='Stack @ BTC > Upper',
    #             zorder=8)
    # ax1.scatter(date_range[below_lower], stack_below,
    #             color='#98df8a', marker='^', label='Stack @ BTC < Lower',
    #             zorder=8)
    ax1.scatter(date_range[above_upper], stack_above,# * 0.9933,
            marker='^', color='black', edgecolors='black',  alpha=0.75,
            linewidths=.4, s=75, label='BTC > Upper', zorder=8)

    ax1.scatter(date_range[below_lower], stack_below,# * 1.0066,
            marker='v', color='gray', edgecolors='black',  alpha=0.75,
            linewidths=.4, s=75, label='BTC < Lower', zorder=8)

    # # â‘  ---- è®¡ç®—å¹³æ»‘åºåˆ— -------------------------------------------------
    # WINDOW = 31          # å¿…é¡»ä¸ºå¥‡æ•°ï¼›æ ¹æ®é‡‡æ ·é¢‘ç‡è‡ªè¡Œæ”¾å¤§/ç¼©å°
    # POLY   = 3

    # s_stack = savgol_filter(stack_profile.values, WINDOW, POLY)
    # s_btc   = savgol_filter(btc_trend.values,     WINDOW, POLY)

    # # â‘¡ ---- åŸå§‹æ›²çº¿ï¼ˆä»ä¿ç•™ï¼Œå¯é€‰æ‹©æ³¨é‡Šæ‰ï¼‰ ------------------------------

    # # â‘¢ ---- å¹³æ»‘æ‹Ÿåˆæ›²çº¿ -------------------------------------------------
    # ax1.plot(date_range, s_stack,  ls='--', color='red',
    #          linewidth=2.5, label='BTC/Others Smoothed')
    # ax1.plot(date_range, s_btc,    ls='--', color='blue',
    #          linewidth=2.5, label='BTC/USDT Smoothed')


    # slope   = savgol_filter(stack_profile.values, WINDOW, POLY, deriv=1)

    # # 2âƒ£ æ‹ç‚¹æ£€æµ‹
    # eps = 1e-4                       # æ–œç‡é˜ˆå€¼ï¼›å¯æŒ‰æ•°æ®é‡çº§è°ƒæ•´
    # sign = np.sign(slope)

    # # è´Ÿâ†’æ­£ ï¼ˆåº•éƒ¨æ‹ç‚¹ï¼‰
    # long_idx = np.where((sign[1:] > 0) & (sign[:-1] < 0) & (np.abs(slope[1:]) > eps))[0] + 1
    # # æ­£â†’è´Ÿ ï¼ˆé¡¶éƒ¨æ‹ç‚¹ï¼‰
    # short_idx = np.where((sign[1:] < 0) & (sign[:-1] > 0) & (np.abs(slope[1:]) > eps))[0] + 1

    # # æ‹ç‚¹æ ‡æ³¨
    # ax1.scatter(date_range[long_idx],  s_stack[long_idx], 
    #             marker='o', color='blue',  s=50, zorder=6, label='Savegol Trend Up')
    # ax1.scatter(date_range[short_idx], s_stack[short_idx],
    #             marker='o', color='red',  s=50, zorder=6, label='Savegol Trend Down')

    
    # â”€â”€ 1. è®¡ç®—æœ€åä¸€ä¸ªå€¼ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    y_last = stack_profile.iloc[-1]  # æˆ– stack_profile[-1]ï¼ˆè‹¥æ˜¯ ndarrayï¼‰
    pct_th = 0.015  # Â±2%
    half_win = 10  # å‰åå„ 10 æ­¥
    full_win = 2 * half_win + 1

    # â”€â”€ 2. æ¡ä»¶â‘ ï¼šä¸æœ€åä¸€ä¸ªå€¼ç›¸å·® â‰¤1% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    mask_1pct = (stack_profile.sub(y_last).abs() <= pct_th * y_last)

    # â”€â”€ 3. æ¡ä»¶â‘¡ï¼šå‰å 10 æ­¥çª—å£å†…æ˜¯æå€¼ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    roll_max = stack_profile.rolling(full_win, center=True, min_periods=1).max()
    roll_min = stack_profile.rolling(full_win, center=True, min_periods=1).min()
    mask_ext = (stack_profile == roll_max) | (stack_profile == roll_min)

    # â”€â”€ 4. ç»¼åˆä¸¤é‡æ¡ä»¶ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    target_idx = mask_1pct & mask_ext

    # â”€â”€ 5. ç»˜åˆ¶ç´«è‰²ä¸‰è§’å½¢ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    ax1.scatter(date_range[target_idx],  # æ¨ªåæ ‡
                stack_profile[target_idx],  # çºµåæ ‡
                color='purple',
                marker='o',
                s=30,
                label=f'Â±1% & local extrema ({half_win}-step)',
                zorder=9)


    
    # ç”»æ°´å¹³çº¿
    ax1.axhline(y=y_last, color='purple', linestyle='--', linewidth=0.8, label=f'Last stack_profile = {y_last:.2f}')

    ax1.plot(date_range, stack_profile, label='BTC/Others Trend', color='green', linewidth=2)
    
    if time_gap.find('h') != -1:
        # â€”â€” 3) ç»˜åˆ¶é»‘è‰²å°åœ†ç‚¹ï¼ˆä¸è¿›å›¾ä¾‹ï¼‰â€”â€”
        ax1.scatter(sp.index[cross_idx], sp.iloc[cross_idx], marker='o', color='black', s=28, zorder=8)


    # ax1.set_xlabel('Date')
    ax1.set_ylabel('Price / Return')
    ax1.grid(alpha=0.3)

    # â”€â”€ 2. ç¬¬äºŒåæ ‡è½´ï¼šMACD & Signal â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    ax2 = ax1.twinx()  # å…±ç”¨ xï¼Œç‹¬ç«‹ y
    bar_w = 0.8



    # â”€â”€ 3. åˆå¹¶å›¾ä¾‹ & ç¾åŒ– â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # h1, l1 = ax1.get_legend_handles_labels()
    # h2, l2 = ax2.get_legend_handles_labels()
    # ax1.legend(h1 + h2, l1 + l2, loc='upper left')

    plt.title(
        f'goodGroup {",".join(good_group)} vs. Top {len(top10_coins)} Coins at {BeijingTime(format="%H:%M:%S")}, BTC: {round(exchange.get_price_now("btc"))} Money:{round(exchange.fetch_balance("USDT"))}, T:{time_gap.upper()}, MC:{round(market_idx_1,4)}')

    plt.tight_layout()
    plt.ylabel('Daily Returns (%)', fontsize=16)
    # plt.legend()
    plt.grid(True)
    out_dir = Path(get_current_dir()) / 'chart_for_group'
    out_dir.mkdir(parents=True, exist_ok=True)
    out = str(out_dir / f'comparison_chart_{prex}_{time_gap}.png')
    plt.savefig(out, dpi=150)  # ä¿å­˜å›¾è¡¨
    # plt.show()
    plt.close('all')  # å…³é—­æ‰€æœ‰å›¾å½¢
    gc.collect()  # å¼ºåˆ¶åƒåœ¾å›æ”¶

    print(len([x for x in goodGroup_returns - average_returns if x >= 0]),
          len([x for x in goodGroup_returns if x >= 0]),
          len([x for x in goodGroup_returns - average_returns if x < 0])
          )


def get_good_bad_coin_group(length=5):
    timeframes = ['1m', '5m', '15m', '1h']
    coins = COINS
    volatilities = {coin: [] for coin in coins}
    if length > len(coins) // 2:
        print(f'å…¨éƒ¨å¸æ•° {len(COINS)}, ä½ éœ€è¦çš„é•¿åº¦æ˜¯:{length}')
    # Fetch data for each coin across each timeframe
    for coin in tqdm(coins, desc='coin process'):
        for timeframe in tqdm(timeframes, desc='time'):
            data = fetch_and_process(coin, timeframe)
            volatility = data['daily_return'].std()  # Calculate standard deviation of daily returns
            volatilities[coin].append(volatility)

    # Calculate average volatility for each coin
    avg_volatilities = {coin: np.mean(stats) for coin, stats in volatilities.items()}

    # Sort coins by their average volatility (ascending order)
    sorted_coins = sorted(avg_volatilities, key=avg_volatilities.get)

    # Select the 5 coins with the highest average volatility
    worst_performance_coins = sorted_coins[:length]
    best_performance_coins = sorted_coins[-length:]
    print("Coins with the worst average volatility:", worst_performance_coins)
    print("Coins with the best average volatility:", best_performance_coins)
    local_bp = Path(get_current_dir()) / 'best_performance_coins.txt'
    with open(str(local_bp), 'w') as f:
        f.write(','.join(best_performance_coins))
    # ä¿æŒåŸæœ‰åŒæ­¥é€»è¾‘ï¼Œä½†ä½¿ç”¨æœ¬åœ°æ–‡ä»¶è·¯å¾„
    os.system(f'scp {str(local_bp)} root@{SERVER_IP}:/root/Quantify/okx')
    return worst_performance_coins, best_performance_coins


def launch_fetchers():
    for tf, sec in TIMEFRAMES.items():
        th = threading.Thread(target=fetch_loop, args=(COINS, tf, sec), daemon=True)
        th.start()
    total = len(TIMEFRAMES) * len(COINS)
    print(f"ğŸš€ å·²å¯åŠ¨ {len(TIMEFRAMES)} æ¡é‡‡é›†çº¿ç¨‹ï¼Œç­‰å¾…é¦–è½®æ•°æ®â€¦")



    # â‘¡ é˜»å¡æ£€æŸ¥ shared_data å®Œæ•´æ€§ -----------------------------------
    while True:
        ready = 0
        for tf in TIMEFRAMES:
            tf_dict = shared_data.get(tf, {})
            for c in COINS:
                df = tf_dict.get(c)
                if df is not None and not df.empty:
                    ready += 1

        pct = ready / total * 100
        print(f"\râ³ æ•°æ®å¡«å……è¿›åº¦: {ready}/{total}  ({pct:5.1f}%)", end='', flush=True)

        if ready == total:
            print("\nâœ… shared_data å·²å°±ç»ªï¼Œå¼€å§‹åç»­é€»è¾‘")
            break
        time.sleep(1)

# ---------------------------------------------------------------
# â‘¡ å¤šå‘¨æœŸä¸€è‡´æ€§æ‰«æ  (ä¿æŒå‰é¢å†™å¥½çš„ scan_coins ä¸å˜)
# ---------------------------------------------------------------
def scan_coins():
    tfs = ['1m', '15m', '1h', '4h', '1d']
    for coin in COINS:                                  # COINS: å…¨éƒ¨å°å†™
        dfs = {}
        try:
            for tf in tfs:
                dfs[tf] = fetch_and_process(coin, tf)
                time.sleep(0.05)                        # èŠ‚æµ
            multi_tf_ma_bBands_signal(
                dfs['1m'], dfs['15m'], dfs['1h'],
                dfs['4h'], dfs['1d'],
                symbol=coin.upper()
            )
        except Exception as e:
            print(f"âŒ {coin.upper()} å¤„ç†å¤±è´¥:", e)

# ---------------------------------------------------------------
# â‘¢ æ¯åˆ†é’Ÿè¿è¡Œä¸€æ¬¡ scan_coins çš„å¾ªç¯çº¿ç¨‹
# ---------------------------------------------------------------
def scan_loop(interval=60):
    while True:
        t0 = time.time()
        scan_coins()
        dt = time.time() - t0
        sleep_sec = max(5, interval - dt)               # è‡³å°‘æ­‡ 5 ç§’
        time.sleep(sleep_sec)


if __name__ == '__main__':
    launch_fetchers()
    # time.sleep(len(COINS) * 1.5)

    start_time = time.time()
   # å°† shared_data ä½œä¸ºå¼•ç”¨ä¼ å…¥
   #  threading.Thread(target=clock_worker, args=(shared_data,), daemon=True).start()
    # å®šä¹‰æ—¶é—´é—´éš”åˆ°æ–‡ä»¶åçš„æ˜ å°„
    timegap_to_filename = {
        '1m':  '1m.png',
        '5m':  '15m.png',
        '15m': '30m.png',
        '1h':  '1H.png',
        '4h':  '4H.png',
        '1d':  '1D.png'
    }
    update_interval = {          # æ¯ä¸ªå‘¨æœŸçš„åˆ·æ–°ç§’æ•°
        '1m': 5,
        '5m': 10,
        '15m':15,
        '1h': 20,
        '4h': 25,
        '1d': 30
    }
    last_run = {g: 0 for g in update_interval}   # åˆå§‹åŒ–
    worst_performance_coins, best_performance_coins = get_good_bad_coin_group(18)
    threading.Thread(target=scan_loop, daemon=True).start()
    for idx, gap in enumerate(['1m','5m','15m','1h','4h','1d']):
        data_frame = {c: fetch_and_process(c, gap) for c in COINS}
        score, ranks, weight = factor_strength_ranking(
            data_frames=data_frame,
            lookback = 60,   # 60 æ ¹Ã—5 min â‰ˆ 5 h
        )

        print(f"{idx}, {gap} ç»¼åˆå¾—åˆ†:\n", score)

        market_idx = market_strength_index(data_frame, lookback=60)
        print(f"å½“å‰å¸‚åœºå¼ºå¼±æŒ‡æ•°ï¼š{market_idx:.4f}")
        # if idx == 5:
        #     clusters = cluster_kline_graph(
        #         data_frame,
        #         lookback   = 60,   # è¿‡å» 60 å¤©
        #         n_clusters = 6     # æƒ³åˆ† 4 ç°‡
        #     )
        #     for cid, members in clusters.items():
        #         print(f"Cluster {cid}: {members}")
    # ---------------------------------------------------------------
    while True:
        try:
        # if 1>0:
            now = time.time()
            for idx, gap in enumerate(['1m','5m','15m','1h','4h','1d']):
                if now - last_run[gap] < update_interval[gap]:
                    continue                      # æœªåˆ°åˆ·æ–°ç‚¹
                if idx == 1:
                    for xx in ['1m', '5m', '15m']:
                        draw_allcoin_trend(xx, COINS)        # COINS æ˜¯ä½ çš„å¸ç§åˆ—è¡¨
                
                # ---------- ç”Ÿæˆå¹¶å‘é€ä¸»å›¾ ----------
                chart_name = f'all_coin-{idx}'
                good_group = list(set(['btc'] + best_performance_coins))
                good_group = []
                main1(COINS, prex=chart_name, time_gap=gap, good_group=good_group, all_rate= [1/len(good_group) for coinx in good_group] )
                out_dir = Path(get_current_dir()) / 'chart_for_group'
                out_dir.mkdir(parents=True, exist_ok=True)
                local = str(out_dir / f'comparison_chart_{chart_name}_{gap}.png')
                remote = timegap_to_filename[gap]
                if HOST_IP.find(SERVER_IP) != -1:
                    os.system(f'cp {local} ~/mysite/static/images/{remote}')
                else:
                    os.system(f'scp {local} root@{SERVER_IP}:/root/mysite/static/images/{remote}')

                last_run[gap] = now              # æ›´æ–°æ—¶é—´æˆ³
                print(f"[{gap}] æ›´æ–°å®Œæˆï¼Œç”¨æ—¶ {round(time.time()-now,2)} ç§’")
                        # ---------- è°ƒç”¨ ----------

            # æ¯æ—¥åˆ·æ–°ä¸€æ¬¡ best / worst ç»„åˆ
            if int(now//3600) != int((now-10)//3600):
                worst_performance_coins, best_performance_coins = get_good_bad_coin_group(18)

            if (now - start_time) % 600 == 0:
                log_asset()
                plot_asset_trend()
        except Exception as e:
            print("ä¸»å¾ªç¯å¼‚å¸¸:", e)

        time.sleep(2)        # è½»é‡è½®è¯¢
